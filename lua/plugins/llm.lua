return {
  "Kurama622/llm.nvim",
  dependencies = { "nvim-lua/plenary.nvim", "MunifTanjim/nui.nvim" },
  cmd = { "LLMSessionToggle", "LLMSelectedTextHandler" },
  config = function()
    require("llm").setup({
      prompt = "You are a helpful chinese assistant.",

      prefix = {
        user = { text = "ğŸ˜ƒ ", hl = "Title" },
        assistant = { text = "âš¡ ", hl = "Added" },
      },

      style = "float", -- right | left | above | below | float

      -- [[ Github Models ]]
      -- url = "https://models.inference.ai.azure.com/chat/completions",
      -- model = "gpt-4o",
      -- api_type = "openai",
      --[[ å¯é€‰çš„: å¦‚æœä½ éœ€è¦åŒæ—¶ä½¿ç”¨ä¸åŒå¹³å°çš„æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡é…ç½®
                     fetch_key æ¥ä¿è¯ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„API Key]]
      -- fetch_key = function()
      --   return switch("enable_gpt")
      -- end,

      -- [[ cloudflare ]]
      -- model = "@cf/google/gemma-7b-it-lora",

      -- [[ ChatGLM ]]
      -- url = "https://open.bigmodel.cn/api/paas/v4/chat/completions",
      -- model = "glm-4-flash",

      -- [[ kimi ]]
      -- url = "https://api.moonshot.cn/v1/chat/completions",
      -- model = "moonshot-v1-8k", -- "moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"
      -- api_type = "openai",

      -- [[ local llm ]]
      -- url = "http://localhost:11434/api/chat",
      -- model = "llama3.2:1b",
      -- api_type = "ollama",

      -- [[ siliconflow ]]
      -- url = "https://api.siliconflow.cn/v1/chat/completions",
      -- api_type = "openai",
      -- model = "Qwen/Qwen2.5-7B-Instruct",
      -- -- [optional: fetch_key]
      -- fetch_key = function()
      --   return switch("enable_siliconflow")
      -- end,

      -- [[ openrouter ]]
      -- url = "https://openrouter.ai/api/v1/chat/completions",
      -- model = "google/gemini-2.0-flash-exp:free",
      -- api_type = "openai",
      -- fetch_key = function()
      --   return switch("enable_openrouter")
      -- end,

      -- [[deepseek]]
      url = "https://api.deepseek.com/chat/completions",
      model = "deepseek-chat",
      api_type = "openai",
      -- api_key é€šè¿‡ .zshrc ä¸­ LLM_KEY ç¯å¢ƒå˜é‡é…ç½®
      -- fetch_key = function()
      --   return switch("enable_deepseek")
      -- end,

      max_tokens = 1024,
      save_session = true,
      max_history = 15,
      history_path = "~/deepseek/chat/history", -- where to save history
      temperature = 0.3,
      top_p = 0.7,

      spinner = {
        text = {
          "î©±ó°§ó°§",
          "ó°§î©±ó°§",
          "ó°§ó°§î©±",
          "ó°§î©±ó°§",
        },
        hl = "Title",
      },

      display = {
        diff = {
          layout = "vertical", -- vertical|horizontal split for default provider
          opts = { "internal", "filler", "closeoff", "algorithm:patience", "followwrap", "linematch:120" },
          provider = "mini_diff", -- default|mini_diff
        },
      },

        -- stylua: ignore
        keys = {
          -- The keyboard mapping for the input window.
          ["Input:Cancel"]      = { mode = "n", key = "<C-c>" },
          ["Input:Submit"]      = { mode = "n", key = "<cr>" },
          ["Input:Resend"]      = { mode = "n", key = "<C-r>" },

          -- only works when "save_session = true"
          ["Input:HistoryNext"] = { mode = "n", key = "<C-j>" },
          ["Input:HistoryPrev"] = { mode = "n", key = "<C-k>" },

          -- The keyboard mapping for the output window in "split" style.
          ["Output:Ask"]        = { mode = "n", key = "i" },
          ["Output:Cancel"]     = { mode = "n", key = "<C-c>" },
          ["Output:Resend"]     = { mode = "n", key = "<C-r>" },

          -- The keyboard mapping for the output and input windows in "float" style.
          ["Session:Toggle"]    = { mode = "n", key = "<leader>ac" },
          ["Session:Close"]     = { mode = "n", key = "<esc>" },
        },
    })
  end,
  keys = {
    { "<leader>ac", mode = "n", "<cmd>LLMSessionToggle<cr>" },
    { "<leader>ae", mode = "v", "<cmd>LLMSelectedTextHandler è¯·è§£é‡Šä¸‹é¢è¿™æ®µä»£ç <cr>" },
    { "<leader>t", mode = "x", "<cmd>LLMSelectedTextHandler è‹±è¯‘æ±‰<cr>" },
  },
}
